{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chicago Data Portal download: https://data.cityofchicago.org/Service-Requests/311-Service-Requests-Pot-Holes-Reported/7as2-ds3y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd~/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a date time for today \n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "today = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "import pandas as pd\n",
    "import datetime\n",
    "data = pd.read_csv('Potholes.csv')\n",
    "#remove duplicated  values\n",
    "data= data[data.STATUS != 'Open - Dup']\n",
    "data = data[data.STATUS != 'Completed - Dup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert creation date to datetime formate\n",
    "data['CREATION DATE'] = pd.to_datetime(data['CREATION DATE'], infer_datetime_format= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert completion date to datetime formate\n",
    "data['COMPLETION DATE'] = pd.to_datetime(data['COMPLETION DATE'], infer_datetime_format= True, errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column where completion dates are all filled\n",
    "#This is help in calculations later on\n",
    "data['COMPLETION_DATE'] = data['COMPLETION DATE'].fillna(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a column calculating the length of time to complete request\n",
    "#Column _na includes NA values\n",
    "data['completion_length_na'] = data['COMPLETION DATE'] - data['CREATION DATE']\n",
    "data['completion_length'] = data['COMPLETION_DATE'] - data['CREATION DATE']\n",
    "#convert new columns into floats for easier calulations \n",
    "data.completion_length = data.completion_length.astype('timedelta64[D]')\n",
    "data.completion_length_na = data.completion_length_na.astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.completion_length_na.describe()\n",
    "data.completion_length.describe()\n",
    "#Almost 400K unique data points\n",
    "#Including NA values increases data set by less than 1%\n",
    "    #more importantly,it does not change the mean or quartile placements\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review boxplots to examin data distribution and ensure adding NA values in does not chance the outlook\n",
    "data.completion_length.value_counts().plot.box(figsize=(7,8)) \n",
    "data.completion_length_na.value_counts().plot.box(figsize=(7,8)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_open = data[data['STATUS'] == 'Open']\n",
    "status_open.completion_length.describe()\n",
    "status_open.completion_length.plot.box()\n",
    "#from the boxplot it appears open requests are mostly older requests\n",
    "#Mean and Median much high than the 99% of completed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.completion_length.skew()\n",
    "#3.29 --> very positively skewed\n",
    "data.completion_length.kurt()\n",
    "#22.29 --> Very long tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few points:\n",
    "1. The city has a fairly successful rate of completion\n",
    "2. The first quartile of data falls within being completed on the first day requested\n",
    "3. Mean > median, showing a positive distribution skew\n",
    "4. NA values in completion length can be included in our computations without effecting the data distribution\n",
    "5. Because of the skewness and many outliers it would be \n",
    "    best to tranform this data for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#A quarter of the data is created and completed within a day\n",
    "#resulting in many 0's in column to be transformed\n",
    "#This is worked around by using a log(x+c) transformation\n",
    "data['log_transformation'] = np.log(data.completion_length +1)\n",
    "data.log_transformation.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.log_transformation.plot.box()\n",
    "#Outliers still present but to a lesser degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.log_transformation.plot.hist()\n",
    "#still positiviley skewed, again to a lesser degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.log_transformation.skew()\n",
    "#.17 --> very close to 0\n",
    "data.log_transformation.kurt()\n",
    "# -1.06 --> kurtosis has been transformed from a leptokurtic distribution\n",
    "#to a platykurtic distribuion, showing less sever tails than a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_quartile = data[data['log_transformation'] <=0.693147]\n",
    "first_quartile = data[data['log_transformation'] <=0.693147]\n",
    "second_quartile = data[(data['log_transformation'] < .693147) & (data['log_transformation'] <= 1.945910)]\n",
    "third_quartile = data[(data['log_transformation'] < 1.945910) & (data['log_transformation'] <= 3.135494)]\n",
    "outliers= data[data['log_transformation'] <=3.135494]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to apply geovisualization for a better understanding of response rate within community locations as well as to locate if there is a reporting pattern.\n",
    "This will be achieve by using the folium mapping package\n",
    "and overlaying heat and distribution maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
